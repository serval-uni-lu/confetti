# Counterfactual Explainable AI (XAI) Method for Deep Learning-Based Multivariate Time Series Classification

This branch contains the code used to reproduce all experiments, evaluations, and figures for CONFETTI's paper. The work was accepted to the AAAI 2026 Technical Main Track. The official publication link will be added here once available.  
An extended version of the paper is available on arXiv: https://arxiv.org/abs/2511.13237

## Abstract
Recent advances in deep learning have improved multivariate time series (MTS) classification and regression by capturing complex patterns, but their lack of transparency hinders decision-making. Explainable AI (XAI) methods offer partial insights, yet often fall short of conveying the full decision space. Counterfactual Explanations (CE) provide a promising alternative, but current approaches typically prioritize either accuracy, proximity or sparsity, limiting their practical value.

To address this, we propose CONFETTI, a multi-objective CE method for MTS. CONFETTI identifies key MTS subsequences, locates a counterfactual target, and optimally modifies the time series to balance prediction confidence, proximity and sparsity. The method provides actionable insights with minimal changes, improving interpretability and decision support. CONFETTI is evaluated on seven MTS datasets from the UEA archive, demonstrating its effectiveness in various domains. CONFETTI consistently outperforms state-of-the-art CE methods in its optimization objectives, and in six additional metrics from the literature, achieving at least 10% higher confidence while improving sparsity by at least 40%.

---

## Installation

CONFETTI uses ``uv`` to manage the environment and dependencies. Make sure you have Python 3.12 or newer.

### 1. Create and activate the environment:

```bash
uv venv
source .venv/bin/activate
```

### 2. Install the base dependencies
These are the dependencies required for the CONFETTI library itself.

```bash
uv sync
```

### 3. Install the CONFETTI package in editable mode
This makes the local source code under ``src/confetti`` importable across all scripts.

```bash
uv pip install -e .
```

### 4. Install the dependencies needed for the paper experiments.
The paper includes comparisons with other methods, statistical tests, figure generation, notebook execution, and other tasks that require additional libraries. These are grouped under the optional ``paper`` dependency group.

```bash
uv sync --group paper
```
After this step, your environment matches the configuration used for all benchmarks, evaluations, and figures in the CONFETTI paper.

## Reproducing the Benchmark
### 1. Generate Counterfactuals
All counterfactual explanations evaluated in the CONFETTI paper can be generated by running the benchmark script located in: ``paper/benchmark/reproduce_benchmark.py``
This script trains the models used in the paper, generates the instances to be explained, and runs every counterfactual method included in the benchmark.

```bash
python paper/benchmark/reproduce_benchmark.py
```
This script performs the following steps:

1. Trains the FCN and ResNet models used in the experiments.

2. Generates the instances to explain for both models.

3. Runs every counterfactual generator:
   * CONFETTI
   * CoMTE
   * TsEVO
   * SETS

*Note: Applies the required TSInterpret patch before running CoMTE.*

Saves all generated counterfactuals under: ``paper/results/``

### 2. Evaluate Counterfactuals
Once all counterfactuals have been generated, you can evaluate them across all datasets, models, explainers, and CONFETTI configurations using the evaluation script located at:
``paper/benchmark/evaluations/evaluations.py``
This script computes all metrics used in the paper, including coverage, sparsity, confidence, proximity, validity, and yNN.
```bash
python paper/benchmark/evaluations/evaluations.py
```

## Minimal Usage Example

The example below shows how to load a trained model, prepare the data, compute the CAM reference weights, and generate counterfactual explanations for a small set of instances using CONFETTI.

```python
import keras
from confetti import CONFETTI
from confetti.explainer.counterfactuals import CounterfactualResults
from paper.CAM import class_activation_map as cam
from paper.utils import load_data
from paper.benchmark.generators.confetti_generator import create_standard_results_dataframe
```
#### Load trained model
```python
model_path = "path/to/my/model"
model = keras.models.load_model(model_path)
```
#### Load data
```python
# Load reference data
X_train, X_test, y_train, y_test = load_data("Libras", one_hot=False)
```

#### Compute CAM weights for the reference data
```python
training_weights = cam.compute_weights_cam(
    model=model,
    X_data=X_train,
    dataset="Libras",
    save_weights=False,
    data_type="training",
)
```

#### Create the explainer
```python
explainer = CONFETTI(model_path)
```

#### Generate counterfactual explanations

```python
counterfactuals = explainer.generate_counterfactuals(
    instances_to_explain=X_test,
    reference_data=X_train,
    reference_weights=training_weights,
)
```
**Important Note:** CONFETTI can be configured with different parameters to adjust the optimization objectives and behavior.
It can also be used with parallelization to speed up the generation of counterfactuals by providing a number of processors to the
parameter ``processes``.

