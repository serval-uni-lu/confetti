{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T12:38:22.859587Z",
     "start_time": "2025-06-25T12:38:11.195736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "from confetti.explainer.utils import *\n",
    "import config as cfg\n",
    "import confetti.CAM.class_activation_map as cam\n",
    "from confetti.explainer.confetti_explainer import CONFETTI\n",
    "from pathlib import Path"
   ],
   "id": "524ec6889b3d5157",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T12:50:36.374880Z",
     "start_time": "2025-06-25T12:50:02.550132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = 'NATOPS'\n",
    "\n",
    "model_path = str(cfg.TRAINED_MODELS_DIR / dataset / f\"{dataset}_resnet.keras\")\n",
    "\n",
    "# load training data and model\n",
    "X_train, X_test, y_train, y_test = load_data(dataset, one_hot=False)\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "# load samples\n",
    "sample_file = f\"{cfg.DATA_DIR}/{dataset}_samples.csv\"\n",
    "X_samples, y_samples = load_multivariate_ts_from_csv(sample_file)\n",
    "\n",
    "#Compute CAM weights\n",
    "training_weights = cam.compute_weights_cam(model=model, X_data=X_train, dataset=dataset,\n",
    "                                                   save_weights=False, data_type='training')\n",
    "\n",
    "#Create CONFETTI explainer\n",
    "ce = CONFETTI(model_path=model_path,\n",
    "              X_test=X_samples,\n",
    "              reference_data=X_train,\n",
    "              weights=training_weights)\n",
    "\n",
    "#Define where to save the counterfactuals\n",
    "ce_dir = Path.cwd()\n",
    "\n",
    "#Generate counterfactuals\n",
    "ces_naive, ces_optimized = ce.parallelized_counterfactual_generator(\n",
    "                ce_dir,\n",
    "                save_counterfactuals=False,\n",
    "                processes=6,\n",
    "                alpha=0.5,\n",
    "                theta=0.75,\n",
    "                verbose=False,\n",
    "            )\n"
   ],
   "id": "dc033f16ad11f796",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability target is 0.75 and the CE is 0.7878276705741882\n",
      "\n",
      "Compiled modules for significant speedup can not be used!\n",
      "https://pymoo.org/installation.html#installation\n",
      "\n",
      "To disable this warning:\n",
      "from pymoo.config import Config\n",
      "Config.warnings['not_compiled'] = False\n",
      "\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T12:50:42.554008Z",
     "start_time": "2025-06-25T12:50:41.930774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from benchmark.evaluations.evaluator import Evaluator\n",
    "\n",
    "og_labels = np.argmax(model.predict(X_samples),axis=1)\n",
    "ev = Evaluator()\n",
    "metrics, summary = ev.evaluate_results(model=model,\n",
    "                                       explainer=\"Confetti\",\n",
    "                                       dataset=\"NATOPS\",\n",
    "                                       counterfactuals=ces_optimized,\n",
    "                                       sample=X_samples,\n",
    "                                       og_labels=og_labels,\n",
    "                                       training_data=X_train,\n",
    "                                       timesteps=51,\n",
    "                                       channels=24,\n",
    "                                       alpha=False,\n",
    "                                       param_config=0.75)\n",
    "\n",
    "summary"
   ],
   "id": "37fea61fb2ebd3b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No counterfactual found for instance 0 in dataset. Skipping...\n",
      "No counterfactual found for instance 1 in dataset. Skipping...\n",
      "No counterfactual found for instance 2 in dataset. Skipping...\n",
      "No counterfactual found for instance 3 in dataset. Skipping...\n",
      "No counterfactual found for instance 4 in dataset. Skipping...\n",
      "No counterfactual found for instance 5 in dataset. Skipping...\n",
      "No counterfactual found for instance 6 in dataset. Skipping...\n",
      "No counterfactual found for instance 7 in dataset. Skipping...\n",
      "No counterfactual found for instance 8 in dataset. Skipping...\n",
      "No counterfactual found for instance 10 in dataset. Skipping...\n",
      "No counterfactual found for instance 11 in dataset. Skipping...\n",
      "No counterfactual found for instance 12 in dataset. Skipping...\n",
      "No counterfactual found for instance 13 in dataset. Skipping...\n",
      "No counterfactual found for instance 14 in dataset. Skipping...\n",
      "No counterfactual found for instance 15 in dataset. Skipping...\n",
      "No counterfactual found for instance 16 in dataset. Skipping...\n",
      "No counterfactual found for instance 17 in dataset. Skipping...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  Explainer Dataset  Coverage  Sparsity  Confidence  Validity  Proximity L1  \\\n",
       "0  Confetti  NATOPS  5.555556  0.919118    0.907845       1.0     45.445621   \n",
       "\n",
       "   Proximity L2  Proximity DTW  yNN  \n",
       "0      5.878509       5.878509  1.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Explainer</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Sparsity</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Validity</th>\n",
       "      <th>Proximity L1</th>\n",
       "      <th>Proximity L2</th>\n",
       "      <th>Proximity DTW</th>\n",
       "      <th>yNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Confetti</td>\n",
       "      <td>NATOPS</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>0.919118</td>\n",
       "      <td>0.907845</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.445621</td>\n",
       "      <td>5.878509</td>\n",
       "      <td>5.878509</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''import config as cfg\n",
    "\n",
    "# Dictionary to store dataset name â†’ (timesteps, features)\n",
    "dataset_shapes = {}\n",
    "\n",
    "for dataset in cfg.DATASETS:\n",
    "    X_training, X_testing, y_training, y_testing = load_data(dataset, one_hot=False)\n",
    "\n",
    "    timesteps = X_training.shape[1]\n",
    "    features = X_training.shape[2]\n",
    "\n",
    "    dataset_shapes[dataset] = (timesteps, features)\n",
    "\n",
    "# Optional: print or return the dictionary\n",
    "print(dataset_shapes)'''"
   ],
   "id": "85d206083fb558c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''from confetti.explainer.utils import convert_string_to_array\n",
    "\n",
    "alphas = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
    "thetas = [0.55, 0.65, 0.75, 0.85, 0.95]\n",
    "#Load conterfactuals saved in cfg.RESULTS_DIR, and obtain the labels of the counterfactuals\n",
    "for dataset in cfg.DATASETS:\n",
    "    model = cfg.TRAINED_MODELS_DIR / dataset / f\"{dataset}_fcn.keras\"\n",
    "    ce_dir = cfg.RESULTS_DIR / dataset\n",
    "    for alpha in alphas:\n",
    "        ces_naive_df = pd.read_csv(ce_dir / f\"confetti_naive_{dataset}_fcn_alpha_{alpha}.csv\")\n",
    "        timesteps = dataset_shapes[dataset][0]\n",
    "        features = dataset_shapes[dataset][1]\n",
    "        ces_naive_df['Solution'] = ces_naive_df['Solution'].apply(lambda s: convert_string_to_array(s, timesteps, features))\n",
    "        ces_naive_df['CE Label'] = ces_naive_df['Solution'].apply(lambda x: np.argmax(model.predict(x.reshape(1, timesteps, channels)), axis=1)[0])\n",
    "\n",
    "'''"
   ],
   "id": "d59d5ec538c40d56",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
